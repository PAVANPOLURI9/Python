import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_text
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Read the dataset
df = pd.read_csv("C:/Users/pavan/OneDrive/Desktop/AI Notes/telecom_churn_data.csv")

# Step 2: Encode categorical variables
label_encoders = {}
for column in df.select_dtypes(include=['object']).columns:
    if column != "Client_Exit":  # Target variable remains unchanged
        le = LabelEncoder()
        df[column] = le.fit_transform(df[column])
        label_encoders[column] = le  # Store encoders for future reference

# Step 3: Define features (X) and target variable (y)
X = df.drop(columns=['Client_Exit'])  # Features (independent variables)
y = df['Client_Exit']  # Target variable (dependent variable)

# Step 4: Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Initialize and train Decision Tree model
clf = DecisionTreeClassifier(random_state=42)
clf.fit(X_train, y_train)

# Step 6: Make predictions on the test set
y_pred = clf.predict(X_test)

# Step 7: Compute confusion matrix
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# Step 8: Calculate required metrics
sensitivity = tp / (tp + fn)  # Sensitivity (Recall)
specificity = tn / (tn + fp)  # Specificity
precision = tp / (tp + fp)  # Precision
npv = tn / (tn + fn)  # Negative Predictive Value
accuracy = (tp + tn) / (tp + tn + fp + fn)  # Accuracy

# Step 9: Display results
print(f"Confusion Matrix:\n{confusion_matrix(y_test, y_pred)}\n")
print(f"True Positives (TP): {tp}")
print(f"False Positives (FP): {fp}")
print(f"True Negatives (TN): {tn}")
print(f"False Negatives (FN): {fn}\n")

print(f"Sensitivity (Recall): {sensitivity:.2f}")
print(f"Specificity: {specificity:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Negative Predictive Value (NPV): {npv:.2f}")
print(f"Accuracy: {accuracy:.2f}\n")

# Step 10: Classification report
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Print the Decision Tree in text format
tree_rules = export_text(clf, feature_names=list(X.columns))
print(tree_rules)

